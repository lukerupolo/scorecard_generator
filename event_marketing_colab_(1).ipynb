{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lukerupolo/scorecard_generator/blob/main/event_marketing_colab_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Install all required packages and configure your ngrok token\n",
        "!pip install -q streamlit pyngrok pandas openpyxl\n",
        "\n",
        "from pyngrok import ngrok, conf\n",
        "# Cell 1: Install all required packages and configure your ngrok token\n",
        "!pip install -q streamlit pyngrok pandas openpyxl\n",
        "\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "# 🔑 Replace this with your actual ngrok Authtoken:\n",
        "!ngrok config add-authtoken 2xyaMUyxj5KM0l5tTL4evh59QfJ_7pmCiswiRKF93Hp3xGZcn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gv7MOUno0wEL",
        "outputId": "e321197b-0269-445b-fca9-205322fddda8"
      },
      "id": "gv7MOUno0wEL",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile event_marketing_app.py\n",
        "# -------------------------------------------------------------\n",
        "# Streamlit – Event Marketing Analytics Suite\n",
        "# Modes:\n",
        "# 1) Generate template       → configure events & download blank workbook\n",
        "# 2) Final benchmarks        → upload completed workbook & download summaries\n",
        "# -------------------------------------------------------------\n",
        "from __future__ import annotations\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from io import BytesIO\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Helpers\n",
        "# ---------------------------------------------------------\n",
        "def format_span_labels(event_date: datetime) -> tuple[str, str]:\n",
        "    b_start = event_date - timedelta(days=7)\n",
        "    b_end   = event_date - timedelta(days=1)\n",
        "    a_end   = event_date + timedelta(days=6)\n",
        "    baseline = f\"Baseline {b_start:%Y-%m-%d} → {b_end:%Y-%m-%d}\"\n",
        "    actual   = f\"Actual  {event_date:%Y-%m-%d} → {a_end:%Y-%m-%d}\"\n",
        "    return baseline, actual\n",
        "\n",
        "def generate_event_tables(events: list[dict], metrics: list[str], countries: list[str]) -> dict[str, pd.DataFrame]:\n",
        "    sheets: dict[str, pd.DataFrame] = {}\n",
        "    for ev in events:\n",
        "        baseline_col, actual_col = format_span_labels(ev[\"date\"])\n",
        "        template = pd.DataFrame({\n",
        "            \"Metric\":          metrics,\n",
        "            baseline_col:       [None] * len(metrics),\n",
        "            actual_col:         [None] * len(metrics),\n",
        "            \"Baseline Method\": [None] * len(metrics),\n",
        "        })\n",
        "        for country in countries:\n",
        "            name = ev[\"name\"][:25] or \"Event\"\n",
        "            sheets[f\"{name}_{country}\"] = template.copy()\n",
        "    return sheets\n",
        "\n",
        "def compute_final_benchmarks(uploaded_file) -> dict[str, pd.DataFrame]:\n",
        "    xls = pd.ExcelFile(uploaded_file)\n",
        "    sheets_all = {sh: pd.read_excel(xls, sh) for sh in xls.sheet_names}\n",
        "    region_groups: dict[str, list[pd.DataFrame]] = {}\n",
        "\n",
        "    for name, df in sheets_all.items():\n",
        "        parts = name.rsplit(\"_\", 1)\n",
        "        if len(parts) != 2:\n",
        "            continue\n",
        "        region_groups.setdefault(parts[1], []).append(df)\n",
        "\n",
        "    summary: dict[str, pd.DataFrame] = {}\n",
        "    for region, dfs in region_groups.items():\n",
        "        metrics_list = dfs[0][\"Metric\"].tolist()\n",
        "        data = {\"Metric\": metrics_list}\n",
        "        avg_actuals, avg_uplift, avg_method = [], [], []\n",
        "\n",
        "        for m in metrics_list:\n",
        "            acts, upls, meths = [], [], []\n",
        "            for df in dfs:\n",
        "                cols = df.columns.tolist()\n",
        "                b_col, a_col = cols[1], cols[2]\n",
        "                meth_col = cols[3] if len(cols) > 3 else None\n",
        "                row = df[df[\"Metric\"] == m]\n",
        "                if row.empty:\n",
        "                    continue\n",
        "                base = row[b_col].iat[0]\n",
        "                act  = row[a_col].iat[0]\n",
        "                acts.append(act)\n",
        "                if meth_col:\n",
        "                    meths.append(row[meth_col].iat[0])\n",
        "                if pd.notna(base) and pd.notna(act):\n",
        "                    upls.append((act - base) / base * 100)\n",
        "\n",
        "            avg_actuals.append(np.nanmean(acts) if acts else np.nan)\n",
        "            avg_method.append(np.nanmean(meths) if meths else np.nan)\n",
        "            avg_uplift.append(np.nanmean(upls) if upls else np.nan)\n",
        "\n",
        "        data[\"Average Actuals\"]        = avg_actuals\n",
        "        data[\"Baseline Method\"]        = avg_method\n",
        "        data[\"Baseline Uplift Expect\"] = avg_uplift\n",
        "        data[\"Proposed Benchmark\"]     = [np.nanmedian([a, b]) for a, b in zip(avg_actuals, avg_method)]\n",
        "        summary[region] = pd.DataFrame(data)\n",
        "\n",
        "    return summary\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Streamlit App\n",
        "# ---------------------------------------------------------\n",
        "st.set_page_config(page_title=\"Event Marketing Analytics\", layout=\"wide\")\n",
        "st.markdown(\n",
        "    \"\"\"\n",
        "# 📊 Event Marketing Analytics Suite\n",
        "\n",
        "Welcome! This tool helps you:\n",
        "\n",
        "1. **Generate** a template workbook to track multiple events and regions.\n",
        "2. **Download** the blank workbook, fill in your data (Baseline, Actual, Baseline Method).\n",
        "3. **Upload** the completed workbook to compute final benchmarks per region.\n",
        "\n",
        "Select a mode below to get started.\n",
        "\"\"\",\n",
        "    unsafe_allow_html=True\n",
        ")\n",
        "\n",
        "mode = st.sidebar.radio(\n",
        "    \"Select an action:\",\n",
        "    [\"Generate template\", \"Final benchmarks\"]\n",
        ")\n",
        "\n",
        "if mode == \"Generate template\":\n",
        "    st.sidebar.header(\"Step 1: Configure template\")\n",
        "    st.sidebar.markdown(\n",
        "        \"\"\"\n",
        "        Specify your event names, start dates, metrics, and regions.\n",
        "        When ready, click **Generate template** to download the Excel file.\n",
        "        \"\"\"\n",
        "    )\n",
        "    n_events = st.sidebar.number_input(\"Quantity of events\", 1, 20, 1)\n",
        "    events: list[dict] = []\n",
        "    for i in range(n_events):\n",
        "        st.sidebar.subheader(f\"Event {i+1}\")\n",
        "        nm = st.sidebar.text_input(\"Name\", key=f\"nm{i}\") or f\"Event{i+1}\"\n",
        "        dt = st.sidebar.date_input(\"Start date (T)\", key=f\"dt{i}\")\n",
        "        if isinstance(dt, list):\n",
        "            dt = dt[0]\n",
        "        events.append({\"name\": nm, \"date\": datetime.combine(dt, datetime.min.time())})\n",
        "    metrics = st.sidebar.multiselect(\n",
        "        \"Metrics to measure:\",\n",
        "        [\n",
        "            \"Sessions\", \"DAU\", \"Revenue\", \"Installs\", \"Retention\", \"Watch Time\", \"ARPU\", \"Conversions\",\n",
        "            \"Video Views (VOD)\", \"Hours Watched (Streams)\", \"Social Mentions\", \"Search Index\",\n",
        "            \"Broadcast TWT\", \"PCCV\", \"AMA\"\n",
        "        ],\n",
        "        default=[\"Sessions\", \"DAU\", \"Revenue\", \"Installs\"]\n",
        "    )\n",
        "    countries = st.sidebar.multiselect(\n",
        "        \"Regions/Countries:\",\n",
        "        [\"US\",\"GB\",\"KR\",\"JP\",\"BR\",\"DE\",\"AU\",\"CA\",\"FR\",\"IN\",\"TH\",\"ID\",\"SA\"],\n",
        "        default=[\"US\",\"GB\",\"AU\"]\n",
        "    )\n",
        "    if st.sidebar.button(\"Generate template 📥\"):\n",
        "        sheets = generate_event_tables(events, metrics, countries)\n",
        "        st.subheader(\"Preview of generated sheets (first 3)\")\n",
        "        for i, (nm, df) in enumerate(sheets.items()):\n",
        "            if i == 3:\n",
        "                st.caption(f\"...and {len(sheets)-3} more sheets\")\n",
        "                break\n",
        "            st.markdown(f\"**{nm}**\")\n",
        "            st.dataframe(df)\n",
        "        buffer = BytesIO()\n",
        "        with pd.ExcelWriter(buffer, engine=\"openpyxl\") as w:\n",
        "            for nm, df in sheets.items():\n",
        "                df.to_excel(w, index=False, sheet_name=nm)\n",
        "        buffer.seek(0)\n",
        "        st.download_button(\n",
        "            \"📥 Download blank template\",\n",
        "            buffer,\n",
        "            \"event_template.xlsx\",\n",
        "            \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"\n",
        "        )\n",
        "\n",
        "else:\n",
        "    st.sidebar.header(\"Step 2: Compute final benchmarks\")\n",
        "    st.sidebar.markdown(\n",
        "        \"\"\"\n",
        "        Upload the completed template workbook (with Baseline, Actual, Baseline Method).\n",
        "        The tool will compute Uplift%, average across events per region, and propose benchmarks.\n",
        "        \"\"\"\n",
        "    )\n",
        "    uploaded = st.file_uploader(\"Upload filled template Excel file\", type=\"xlsx\")\n",
        "    if uploaded:\n",
        "        summaries = compute_final_benchmarks(uploaded)\n",
        "        st.subheader(\"Summary tables by region\")\n",
        "        for region, df in summaries.items():\n",
        "            st.markdown(f\"### {region}\")\n",
        "            st.dataframe(df)\n",
        "        out = BytesIO()\n",
        "        with pd.ExcelWriter(out, engine=\"openpyxl\") as w:\n",
        "            for region, df in summaries.items():\n",
        "                df.to_excel(w, index=False, sheet_name=region)\n",
        "        out.seek(0)\n",
        "        st.download_button(\n",
        "            \"📥 Download final benchmarks\",\n",
        "            out,\n",
        "            \"final_benchmarks.xlsx\",\n",
        "            \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"\n",
        "        )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA_E5LHI0xyI",
        "outputId": "f09f0e95-5d34-4b9d-ddef-b6c3e4cc56ac"
      },
      "id": "bA_E5LHI0xyI",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing event_marketing_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# ── Step 1: Kill any existing Streamlit processes ────────────\n",
        "os.system(\"pkill -f streamlit\")\n",
        "time.sleep(1)\n",
        "\n",
        "# ── Step 2: Start Streamlit in the background via python -m ────\n",
        "cmd = (\n",
        "    \"nohup python3 -m streamlit run event_marketing_app.py \"\n",
        "    \"--server.port 8501 \"\n",
        "    \"--server.headless true \"\n",
        "    \"--server.address 0.0.0.0 \"\n",
        "    \"--server.enableCORS false \"\n",
        "    \"--server.enableXsrfProtection false \"\n",
        "    \"> streamlit.log 2>&1 &\"\n",
        ")\n",
        "os.system(cmd)\n",
        "time.sleep(5)  # wait for Streamlit to spin up\n",
        "\n",
        "# ── Optional debug prints ─────────────────────────────────────\n",
        "print(\"❓ Streamlit processes:\")\n",
        "os.system(\"ps -ax | grep '[s]treamlit' || echo '→ none'\")\n",
        "\n",
        "print(\"\\n❓ Ports listening on 8501:\")\n",
        "os.system(\"netstat -nlp 2>/dev/null | grep 8501 || echo '→ nothing listening'\")\n",
        "\n",
        "print(\"\\n📄 First 10 lines of streamlit.log:\")\n",
        "os.system(\"head -n 10 streamlit.log || echo '→ streamlit.log missing'\")\n",
        "\n",
        "# ── Step 3: Open (or reuse) a single ngrok tunnel ─────────────\n",
        "tunnels = ngrok.get_tunnels()\n",
        "if tunnels:\n",
        "    public_url = tunnels[0].public_url\n",
        "else:\n",
        "    public_url = ngrok.connect(8501, bind_tls=True).public_url\n",
        "\n",
        "print(f\"\\n🌐 Your Streamlit app is live at: {public_url}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-onjAKZ0yqR",
        "outputId": "666d6662-db95-4f00-fd05-40ff2b0dcdaa"
      },
      "id": "x-onjAKZ0yqR",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❓ Streamlit processes:\n",
            "\n",
            "❓ Ports listening on 8501:\n",
            "\n",
            "📄 First 10 lines of streamlit.log:\n",
            "\n",
            "🌐 Your Streamlit app is live at: https://15d3-34-53-39-133.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "        streamlit==1.35.0\n",
        "        pandas==2.2.2\n",
        "        openpyxl==3.1.2\n",
        "        numpy==1.26.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5X2yhknWFKM",
        "outputId": "0837e4dc-6933-4593-e728-02398fcf2895"
      },
      "id": "N5X2yhknWFKM",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting requirements.txt\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}